{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Aggregator\n",
    "\n",
    "### Project submission group\n",
    "- Group member 1\n",
    "    - Name: Pinkesh Nayak\n",
    "    - Email: prn33@drexel.edu\n",
    "- Group member 2\n",
    "    - Name: Hemachandar Nagarajan\n",
    "    - Email: hn395@drexel.edu\n",
    "- Group member 3\n",
    "    - Name: Sahibzada Aasim Imtiyaz\n",
    "    - Email: si339@drexel.edu\n",
    "- Group member 4\n",
    "    - Name: Pawan Punera\n",
    "    - Email: pp592@drexel.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <i> <span style=\"color:green\"> For this project, we are creating a prototype for which we considered only data science related jobs in United States. <br> These both fields, job category and location are customizable. <br> </span> <i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import robotexclusionrulesparser\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "import csv\n",
    "import dateutil.parser as dateparser\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from dateutil import tz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randstad: Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking `robots.txt` file of Staffing firm [Randstad](https://www.randstad.com) to check whether we can scrape the data from its website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-agent: *\r\n",
      "Sitemap: https://www.randstad.com/sitemap.xml\r\n",
      "\r\n",
      "User-agent: msnbot\r\n",
      "Crawl-delay: 5\r\n",
      "\r\n",
      "User-agent: MJ12bot\r\n",
      "Crawl-Delay: 5\r\n",
      "\r\n",
      "User-agent: bingbot\r\n",
      "Crawl-delay: 5\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.randstad.com/robots.txt\"\n",
    "\n",
    "# Make the request\n",
    "req = urllib.request.Request(url = url)\n",
    "\n",
    "# Open the URL\n",
    "handler = urllib.request.urlopen(req)\n",
    "\n",
    "# Read/view the data as a string\n",
    "robots = handler.read().decode('utf-8')\n",
    "print(robots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output Randstad allows scraping of data with crawl delay of 5 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Using `robotexclusionrulesparser.RobotFileParserLookalike()` to confirm that we're allowed to search job page on Randstad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "## spin up the module\n",
    "rp = robotexclusionrulesparser.RobotFileParserLookalike()\n",
    "\n",
    "## parse the robots file\n",
    "print(rp.can_fetch(\"*\", \"https://www.randstad.com/jobs/united-states/q-data-science/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating directory structures for collection of data from Randstad. \n",
    "Storing data in './data/ranstad/randstad.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/ranstad/\"\n",
    "randstad_filename = \"randstad.csv\"\n",
    "randstand_header = [\"company\",\"title\",\"location\",\"link\",\"job_posted\",\"description\",\"category\",\"source\"]\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "if not os.path.isfile(path+randstad_filename):\n",
    "    with open(path+randstad_filename, 'w', newline='') as file_handle:\n",
    "        writer = csv.writer(file_handle, delimiter=',')\n",
    "        writer.writerow(randstand_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to fetch required data from a page for a particular job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeDataFromPage(page, writer):\n",
    "\n",
    "    html = requests.get(page).text\n",
    "    soup2 = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    job_role = soup2.find('h1').find('span').text\n",
    "\n",
    "    job_details = soup2.find('div', \"cf job-company-logo-summary\").find('dl')\n",
    "\n",
    "    dts = {dt.text.strip() : dt.findNext(\"dd\").text.strip() for dt in job_details.find_all('dt')}\n",
    "    date_posted = dateparser.parse(dts.get('posted'))\n",
    "    location = dts.get('location')\n",
    "    job_category = dts.get('job category')\n",
    "    #job_type = dts.get('job type')\n",
    "    #working_hours = dts.get('working hours')\n",
    "    #salary = dts.get('salary')\n",
    "    source = \"Randstad\"\n",
    "    company_name = \"RANDSTAD PROFESSIONALS US L P\"\n",
    "    job_description = soup2.find('div', {\"id\" : \"js_description\"}).text\n",
    "    \n",
    "    row = [company_name,job_role,location,page,date_posted,job_description,job_category,source]\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to get link of every jobs present on [search pages](https://www.randstad.com/jobs/united-states/q-data-science/)  and calling above function `scrapeDataFromPage()`.\n",
    "NOTE: Below fucntion is only called only once to fetch all the data science jobs in US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchDataFromRandstad():\n",
    "    country = \"united-states\"\n",
    "    job_category = \"data-science\"\n",
    "\n",
    "    randstad_url = \"https://www.randstad.com/jobs/{}/q-{}/\".format(country, job_category)\n",
    "\n",
    "    #total_jobs = int(soup.find(\"div\", \"job-search-header-jobs\").find('span').text.split(\" jobs\")[0])\n",
    "    crawl_delay = 5\n",
    "    header = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "    next_page = randstad_url\n",
    "\n",
    "    randstad_part_url = \"https://www.randstad.com\"\n",
    "    randstad_filename = \"./data/ranstad/randstad.csv\"\n",
    "\n",
    "    with open(randstad_filename, 'a', newline='') as file_handle:\n",
    "        writer = csv.writer(file_handle, delimiter=',')\n",
    "\n",
    "        while True:\n",
    "            randstad_html = requests.get(next_page, headers = header).text\n",
    "            soup = BeautifulSoup(randstad_html, 'html.parser')\n",
    "\n",
    "            for result_link in soup.find(\"section\", \"job-search-results\").find_all(\"header\", \"cf\"):\n",
    "                scrapeDataFromPage(randstad_part_url + result_link.find(\"a\").get(\"href\"), writer)\n",
    "                time.sleep(crawl_delay + random.randrange(1, 10))\n",
    "\n",
    "            is_next = soup.find(\"a\", \"results-pager-next-prev icon-arrow-right\")\n",
    "\n",
    "            if is_next:\n",
    "                next_page = randstad_part_url + soup.find(\"a\", \"results-pager-next-prev icon-arrow-right\").get(\"href\")\n",
    "                time.sleep(crawl_delay + random.randrange(1, 10))\n",
    "            else:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetchDataFromRandstad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Once we fetch all the data using the above function, we need to update our data.\n",
    "Ranstad provides [RSS feeds](https://www.randstad.com/jobs/rss/united-states/q-data-science/) of the recent updated data. \n",
    "We can create python script file with below code and set a cron utility<br> `@hourly python3 fetchDataFromRandstadRSS.py` to perform our scraping once hourly from the RSS feeds. <br> We can compare `pubDate` present in feeds with the time the cron utility last ran and only fetch the latest records link and call function `scrapeDataFromPage()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchDataFromRandstadRSS():\n",
    "    country = \"united-states\"\n",
    "    job_category = \"data-science\"\n",
    "    crawl_delay = 5\n",
    "\n",
    "    randstad_rss_url = \"https://www.randstad.com/jobs/rss/{}/q-{}/\".format(country, job_category)\n",
    "    current_time = datetime.datetime.now()\n",
    "    previous_hour = current_time - datetime.timedelta(hours=1)\n",
    "\n",
    "    previous_hour_utc = previous_hour.astimezone(datetime.timezone.utc)\n",
    "\n",
    "    randstad_rss_html = requests.get(randstad_rss_url).text\n",
    "    rss_soup = BeautifulSoup(randstad_rss_html, 'html.parser')\n",
    "    randstad_filename = \"./data/ranstad/randstad.csv\"\n",
    "\n",
    "    with open(randstad_filename, 'a', newline='') as file_handle:\n",
    "        writer = csv.writer(file_handle, delimiter=',')\n",
    "        for item in rss_soup.find_all(\"item\"):\n",
    "            pubdate = item.find(\"pubdate\").text\n",
    "            pubdate = dateparser.parse(pubdate)\n",
    "            if pubdate >= previous_hour_utc:\n",
    "                rss_link = item.find(\"link\").next_sibling.string.strip()\n",
    "                scrapeDataFromPage(rss_link, writer)\n",
    "                time.sleep(crawl_delay + random.randrange(1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetchDataFromRandstadRSS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adzuna API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After checking [Terms of use](https://developer.adzuna.com/docs/terms_of_service) and [Adzuna API page](https://developer.adzuna.com/overview), we found that there are no rate limits for using its API. Also, it states that it may be used for personal or academic research. We have created developer account and recieved an `app_key` and `aap_id` to access the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating directory structures for collection of data from Adzuna. \n",
    "Storing data in './data/adzuna/adzuna.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/adzuna/\"\n",
    "adzuna_filename = \"adzuna.csv\"\n",
    "adzuna_header = [\"company\",\"title\",\"location\",\"link\",\"job_posted\",\"description\",\"category\",\"source\"]\n",
    " \n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "if not os.path.isfile(path+adzuna_filename):\n",
    "    with open(path+adzuna_filename, 'w', newline='') as file_handle:\n",
    "        writer = csv.writer(file_handle, delimiter=',')\n",
    "        writer.writerow(adzuna_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining fucntion `fetchDataFromAdzuna()` to get job listings from its [API](https://api.adzuna.com/v1/api/jobs/us/search/1?app_id=a4f5ad31&app_key=34579444c00900f8fa58b004dc308aff&what=data%20science&where=us).\n",
    "Checking for all the number of pages present and fetching all job listings from each page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchDataFromAdzuna(max_days_old = 0):\n",
    "    \n",
    "    country = \"us\"\n",
    "    APP_id = 'a4f5ad31'\n",
    "    APP_key = '34579444c00900f8fa58b004dc308aff'\n",
    "    what = \"data science\"\n",
    "    where = \"us\"\n",
    "    adzuna_url = \"https://api.adzuna.com/v1/api/jobs/{}/search/{}?app_id={}&app_key={}&what={}&where={}&max_days_old={}\"\n",
    "    response = requests.get(adzuna_url.format(country,1,APP_id, APP_key, what, where,max_days_old))\n",
    "    results= response.json()\n",
    "    total_jobs = results.get('count')\n",
    "    time.sleep(5)\n",
    "    \n",
    "    with open(\"./data/adzuna/adzuna.csv\", 'a', newline='') as file_handle:\n",
    "        writer = csv.writer(file_handle, delimiter=',')\n",
    "    \n",
    "        for page in range(1,total_jobs+1):\n",
    "            response = requests.get(adzuna_url.format(country,page,APP_id, APP_key, what, where,max_days_old))\n",
    "            results= response.json()\n",
    "            for result in results['results']:\n",
    "                if result.get('title'):\n",
    "                    title = BeautifulSoup(result['title']).get_text()\n",
    "                if result.get('description'):\n",
    "                    description = BeautifulSoup(result['description']).get_text()\n",
    "                row_values = [result['company'].get('display_name'),\n",
    "                                      title,\n",
    "                                      result['location'].get('display_name'),\n",
    "                                      result['redirect_url'],\n",
    "                                      dateparser.parse(result[\"created\"]),\n",
    "                                      description,\n",
    "                                      result['category']['label'],\n",
    "                                      'Adzuna']\n",
    "\n",
    "                try:\n",
    "                    writer.writerow(row_values)\n",
    "                except UnicodeEncodeError:\n",
    "                    row = [item.encode('utf-8') if item and not isinstance(item, datetime.datetime) else item for item in row_values]\n",
    "                    writer.writerow(row)\n",
    "\n",
    "            time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetchDataFromAdzuna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Once we fetch all the data using the above function, we need to update our data.\n",
    "Adzuna provides parameter `max_days_old` in its API which can be used to get latest data by providing the number of days, so if we give value as 1, it will fetch all data from previous day till today.\n",
    "We can create python script file which includes the above function `fetchDataFromAdzuna()`  and set a cron utility<br> `@daily python3 fetchDataFromAdzuna.py` to fetch updated data daily from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetchDataFromAdzuna(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GitHub API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We checked [Terms of use](https://help.github.com/en/github/site-policy/github-terms-of-service#h-api-terms). GitHub's API  doesn't require an \"access token\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating directory structures for collection of data from GitHub. \n",
    "Storing data in './data/github/github.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/github/\"\n",
    "github_filename = \"github.csv\"\n",
    "github_header = [\"company\",\"title\",\"location\",\"link\",\"job_posted\",\"description\",\"category\",\"source\"]\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "if not os.path.isfile(path+github_filename):\n",
    "    with open(path+github_filename, 'w', newline='') as file_handle:\n",
    "        writer = csv.writer(file_handle, delimiter=',')\n",
    "        writer.writerow(github_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining fucntion `fetchDataFromGithub()` to get job listings from its [API](https://jobs.github.com/positions.json?description=data+science&location=US).\n",
    "Checking for all the number of pages present and fetching all job listings from each page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchDataFromGithub():\n",
    "    \n",
    "    location = \"us\"\n",
    "    job = \"data science\"\n",
    "    github_url = \"https://jobs.github.com/positions.json?{}&location={}&page={}\"\n",
    "    \n",
    "    with open(\"./data/github/github.csv\", 'a', newline='') as file_handle:\n",
    "        writer = csv.writer(file_handle, delimiter=',')\n",
    "    \n",
    "        page_count = 1\n",
    "    \n",
    "        while True:\n",
    "            response = requests.get(github_url.format(job,location,page_count))\n",
    "            results = response.json()\n",
    "            \n",
    "            if len(results) != 0:\n",
    "                page_count += 1\n",
    "                for result in results:\n",
    "                    if result.get('title'):\n",
    "                        title = BeautifulSoup(result['title']).get_text()\n",
    "                    if result.get('description'):\n",
    "                        description = BeautifulSoup(result['description']).get_text()\n",
    "                    row_values = [result['company'],\n",
    "                                          title,\n",
    "                                          result['location'],\n",
    "                                          result['url'],\n",
    "                                          dateparser.parse(result[\"created_at\"]),\n",
    "                                          description,\n",
    "                                          \"\",\n",
    "                                          'GitHub']\n",
    "\n",
    "                    try:\n",
    "                        writer.writerow(row_values)\n",
    "                    except UnicodeEncodeError:\n",
    "                        row = [item.encode('utf-8') if item and not isinstance(item, datetime.datetime) else item for item in row_values]\n",
    "                        writer.writerow(row)\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetchDataFromGithub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Muse API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After checking [Terms of use](https://www.themuse.com/developers/api/v2/termse) and [The Muse API page](https://www.themuse.com/developers/api/v2), If we don't register our app, we are limited to 500 requests per hour. We have created developer account and recieved an `app_key` which will allow us to make up to 3600 requests per hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating directory structures for collection of data from 'The Muse'. \n",
    "Storing data in './data/muse/muse.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/muse/\"\n",
    "muse_filename = \"muse.csv\"\n",
    "muse_header = [\"company\",\"title\",\"location\",\"link\",\"job_posted\",\"description\",\"category\",\"source\"]\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "if not os.path.isfile(path+muse_filename):\n",
    "    with open(path+muse_filename, 'w', newline='') as file_handle:\n",
    "        writer = csv.writer(file_handle, delimiter=',')\n",
    "        writer.writerow(muse_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining fucntion `fetchDataFromMuse()` to get job listings from its [API](https://www.themuse.com/api/public/jobs?category=Data%20Science&location=United%20States&page=1).\n",
    "Checking for all the number of pages present and fetching all job listings from each page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchDataFromMuse():\n",
    "    \n",
    "    what = \"Data Science\"\n",
    "    location = \"United States\"\n",
    "    APP_key = 'aee960065c38dee83e8a6f9af40f86c7bb89843d3faf60230066b36418cf6257'\n",
    "    muse_url = \"https://www.themuse.com/api/public/jobs?category={}&location={}&page={}&app_key={}\"\n",
    "    response = requests.get(muse_url.format(what,location,1,APP_key))\n",
    "    request_per_hour = int(response.headers['X-RateLimit-Remaining'])\n",
    "    results= response.json()\n",
    "    page_count = results.get('page_count')\n",
    "    time.sleep(5)\n",
    "    \n",
    "    with open(\"./data/muse/muse.csv\", 'a', newline='') as file_handle:\n",
    "        writer = csv.writer(file_handle, delimiter=',')\n",
    "    \n",
    "        for page in range(1,page_count+1):\n",
    "            if page < request_per_hour:\n",
    "                response = requests.get(muse_url.format(what,location,page,APP_key))\n",
    "                results= response.json()\n",
    "                for result in results['results']:\n",
    "                    if result.get('contents'):\n",
    "                        description = BeautifulSoup(result['contents']).get_text()\n",
    "                    else:\n",
    "                        description = \"\"\n",
    "                    row_values = [result['company'].get('name'),\n",
    "                                          result.get('name'),\n",
    "                                          result['locations'][0].get('name'),\n",
    "                                          result['refs'].get('landing_page'),\n",
    "                                          dateparser.parse(result[\"publication_date\"]),\n",
    "                                          description,\n",
    "                                          result['categories'][0].get('name'),\n",
    "                                          'The Muse']\n",
    "\n",
    "                    try:\n",
    "                        writer.writerow(row_values)\n",
    "                    except UnicodeEncodeError:\n",
    "                        row = [item.encode('utf-8') if item and not isinstance(item, datetime.datetime) else item for item in row_values]\n",
    "                        writer.writerow(row)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "            time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetchDataFromMuse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## United States Citizenship and Immigration Services (USCIS) H1B data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are fetching 2019 H-1B Employer Data which is openly available on [USCIS Website](https://www.uscis.gov/tools/reports-studies/h-1b-employer-data-hub-files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchDataFromUSCIS():\n",
    "    path = \"./data/uscis/\"\n",
    "    uscis_filename = \"uscis.csv\"\n",
    "    uscis_url = \"https://www.uscis.gov/sites/default/files/USCIS/Data/Employment-based/H-1B/h1b_datahubexport-2019.csv\"\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    uscis_response = requests.get(uscis_url)\n",
    "    uscis_text = uscis_response.text.strip().split(\"\\n\")\n",
    "    uscis_reader = csv.reader(uscis_text)\n",
    "    uscis_data = list(uscis_reader)\n",
    "    with open(path+uscis_filename, 'w', newline='') as file_handle:\n",
    "        writer = csv.writer(file_handle, delimiter=',')\n",
    "        writer.writerows(uscis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetchDataFromUSCIS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying Randstad jobs data which we stored in the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>link</th>\n",
       "      <th>job_posted</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>RANDSTAD PROFESSIONALS US L P</td>\n",
       "      <td>sr. data scientist</td>\n",
       "      <td>new york</td>\n",
       "      <td>https://www.randstad.com/jobs/united-states/sr...</td>\n",
       "      <td>2020-06-04</td>\n",
       "      <td>job summary:Our client is looking for dynamic,...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Randstad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RANDSTAD PROFESSIONALS US L P</td>\n",
       "      <td>business intelligence  analyst</td>\n",
       "      <td>kansas city, missouri</td>\n",
       "      <td>https://www.randstad.com/jobs/united-states/bu...</td>\n",
       "      <td>2020-06-05</td>\n",
       "      <td>job summary:Randstad Technologies is looking f...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Randstad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RANDSTAD PROFESSIONALS US L P</td>\n",
       "      <td>people research scientist</td>\n",
       "      <td>menlo park, california</td>\n",
       "      <td>https://www.randstad.com/jobs/united-states/pe...</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>job summary:Are you a PhD or Master with exper...</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Randstad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RANDSTAD PROFESSIONALS US L P</td>\n",
       "      <td>people research scientist</td>\n",
       "      <td>new york</td>\n",
       "      <td>https://www.randstad.com/jobs/united-states/pe...</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>job summary:Are you a PhD or Master with exper...</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Randstad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RANDSTAD PROFESSIONALS US L P</td>\n",
       "      <td>people research scientist</td>\n",
       "      <td>seattle, washington</td>\n",
       "      <td>https://www.randstad.com/jobs/united-states/pe...</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>job summary:Are you a PhD or Master with exper...</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Randstad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         company                           title  \\\n",
       "0  RANDSTAD PROFESSIONALS US L P              sr. data scientist   \n",
       "1  RANDSTAD PROFESSIONALS US L P  business intelligence  analyst   \n",
       "2  RANDSTAD PROFESSIONALS US L P       people research scientist   \n",
       "3  RANDSTAD PROFESSIONALS US L P       people research scientist   \n",
       "4  RANDSTAD PROFESSIONALS US L P       people research scientist   \n",
       "\n",
       "                 location                                               link  \\\n",
       "0                new york  https://www.randstad.com/jobs/united-states/sr...   \n",
       "1   kansas city, missouri  https://www.randstad.com/jobs/united-states/bu...   \n",
       "2  menlo park, california  https://www.randstad.com/jobs/united-states/pe...   \n",
       "3                new york  https://www.randstad.com/jobs/united-states/pe...   \n",
       "4     seattle, washington  https://www.randstad.com/jobs/united-states/pe...   \n",
       "\n",
       "  job_posted                                        description  \\\n",
       "0 2020-06-04  job summary:Our client is looking for dynamic,...   \n",
       "1 2020-06-05  job summary:Randstad Technologies is looking f...   \n",
       "2 2020-05-26  job summary:Are you a PhD or Master with exper...   \n",
       "3 2020-05-26  job summary:Are you a PhD or Master with exper...   \n",
       "4 2020-05-26  job summary:Are you a PhD or Master with exper...   \n",
       "\n",
       "                 category    source  \n",
       "0  Information Technology  Randstad  \n",
       "1  Information Technology  Randstad  \n",
       "2         Human Resources  Randstad  \n",
       "3         Human Resources  Randstad  \n",
       "4         Human Resources  Randstad  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randstad = pd.read_csv(\"./data/ranstad/randstad.csv\", sep = \",\", header = 0, parse_dates = [4], encoding = \"ISO-8859-1\")\n",
    "randstad.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying Adzuna jobs data which we stored in the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>link</th>\n",
       "      <th>job_posted</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Home Depot</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Houston, Texas County</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1373178326?se=Y...</td>\n",
       "      <td>2019-12-13 13:57:49+00:00</td>\n",
       "      <td>POSITION PURPOSE A Data Scientist leverages th...</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Home Depot</td>\n",
       "      <td>Data Scientist, Pricing</td>\n",
       "      <td>Atlanta, Fulton County</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1494906867?se=Y...</td>\n",
       "      <td>2020-03-18 15:45:03+00:00</td>\n",
       "      <td>Position Purpose A Data Scientist leverages th...</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Home Depot</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Atlanta, Fulton County</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1571930776?se=Y...</td>\n",
       "      <td>2020-06-12 19:38:04+00:00</td>\n",
       "      <td>POSITION PURPOSE The Associate Data Scientist ...</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Home Depot</td>\n",
       "      <td>Data Scientist - Supply Chain</td>\n",
       "      <td>Atlanta, Fulton County</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1534472383?se=Y...</td>\n",
       "      <td>2020-05-01 19:07:09+00:00</td>\n",
       "      <td>POSITION PURPOSE: A Data Scientist leverages t...</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Home Depot</td>\n",
       "      <td>Principal Engineer - Data Science</td>\n",
       "      <td>Atlanta, Fulton County</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1430632954?se=Y...</td>\n",
       "      <td>2020-01-31 14:43:08+00:00</td>\n",
       "      <td>Position Purpose : A Principal Data Scientist ...</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      company                              title                location  \\\n",
       "0  Home Depot                     Data Scientist   Houston, Texas County   \n",
       "1  Home Depot            Data Scientist, Pricing  Atlanta, Fulton County   \n",
       "2  Home Depot           Associate Data Scientist  Atlanta, Fulton County   \n",
       "3  Home Depot      Data Scientist - Supply Chain  Atlanta, Fulton County   \n",
       "4  Home Depot  Principal Engineer - Data Science  Atlanta, Fulton County   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.adzuna.com/land/ad/1373178326?se=Y...   \n",
       "1  https://www.adzuna.com/land/ad/1494906867?se=Y...   \n",
       "2  https://www.adzuna.com/land/ad/1571930776?se=Y...   \n",
       "3  https://www.adzuna.com/land/ad/1534472383?se=Y...   \n",
       "4  https://www.adzuna.com/land/ad/1430632954?se=Y...   \n",
       "\n",
       "                 job_posted  \\\n",
       "0 2019-12-13 13:57:49+00:00   \n",
       "1 2020-03-18 15:45:03+00:00   \n",
       "2 2020-06-12 19:38:04+00:00   \n",
       "3 2020-05-01 19:07:09+00:00   \n",
       "4 2020-01-31 14:43:08+00:00   \n",
       "\n",
       "                                         description category  source  \n",
       "0  POSITION PURPOSE A Data Scientist leverages th...  IT Jobs  Adzuna  \n",
       "1  Position Purpose A Data Scientist leverages th...  IT Jobs  Adzuna  \n",
       "2  POSITION PURPOSE The Associate Data Scientist ...  IT Jobs  Adzuna  \n",
       "3  POSITION PURPOSE: A Data Scientist leverages t...  IT Jobs  Adzuna  \n",
       "4  Position Purpose : A Principal Data Scientist ...  IT Jobs  Adzuna  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adzuna = pd.read_csv(\"./data/adzuna/adzuna.csv\", sep = \",\", header = 0, parse_dates = [4], encoding = \"ISO-8859-1\")\n",
    "adzuna.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying GitHub jobs data which we stored in the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>link</th>\n",
       "      <th>job_posted</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>BlueVolt</td>\n",
       "      <td>Senior Software Engineer (.NET)</td>\n",
       "      <td>Portland, OR, US</td>\n",
       "      <td>https://jobs.github.com/positions/8db5942d-34b...</td>\n",
       "      <td>2020-06-12 21:52:25+00:00</td>\n",
       "      <td>Position Summary\\nBlueVolt is growing. We have...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GitHub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Lawrence Berkeley National Laboratory</td>\n",
       "      <td>Web Developer (The Materials Project)</td>\n",
       "      <td>Berkeley</td>\n",
       "      <td>https://jobs.github.com/positions/f1759f8d-107...</td>\n",
       "      <td>2020-06-12 21:15:38+00:00</td>\n",
       "      <td>Web Developer (The Materials Project) - 90287\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GitHub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Game Closure</td>\n",
       "      <td>Senior Game Engineer (REMOTE)</td>\n",
       "      <td>San Francisco, Mountain View, Tokyo, Remote</td>\n",
       "      <td>https://jobs.github.com/positions/e9e632a7-c75...</td>\n",
       "      <td>2019-08-03 00:50:23+00:00</td>\n",
       "      <td>GAME CLOSURE\\nSan Francisco, Mountain View, To...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GitHub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Defendify</td>\n",
       "      <td>Full Stack Engineer</td>\n",
       "      <td>Maine</td>\n",
       "      <td>https://jobs.github.com/positions/7e5a0fb2-778...</td>\n",
       "      <td>2020-06-05 18:53:43+00:00</td>\n",
       "      <td>Thanks for your interest in working with us! D...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GitHub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Kasisto</td>\n",
       "      <td>Front-End Software Engineer</td>\n",
       "      <td>New York</td>\n",
       "      <td>https://jobs.github.com/positions/90b7a228-a21...</td>\n",
       "      <td>2020-06-03 19:36:58+00:00</td>\n",
       "      <td>Humanizing Digital Experiences®\\nKasistos Dig...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GitHub</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  company  \\\n",
       "0                                BlueVolt   \n",
       "1  Lawrence Berkeley National Laboratory    \n",
       "2                            Game Closure   \n",
       "3                               Defendify   \n",
       "4                                 Kasisto   \n",
       "\n",
       "                                    title  \\\n",
       "0         Senior Software Engineer (.NET)   \n",
       "1  Web Developer (The Materials Project)    \n",
       "2           Senior Game Engineer (REMOTE)   \n",
       "3                     Full Stack Engineer   \n",
       "4             Front-End Software Engineer   \n",
       "\n",
       "                                      location  \\\n",
       "0                             Portland, OR, US   \n",
       "1                                     Berkeley   \n",
       "2  San Francisco, Mountain View, Tokyo, Remote   \n",
       "3                                        Maine   \n",
       "4                                     New York   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://jobs.github.com/positions/8db5942d-34b...   \n",
       "1  https://jobs.github.com/positions/f1759f8d-107...   \n",
       "2  https://jobs.github.com/positions/e9e632a7-c75...   \n",
       "3  https://jobs.github.com/positions/7e5a0fb2-778...   \n",
       "4  https://jobs.github.com/positions/90b7a228-a21...   \n",
       "\n",
       "                 job_posted  \\\n",
       "0 2020-06-12 21:52:25+00:00   \n",
       "1 2020-06-12 21:15:38+00:00   \n",
       "2 2019-08-03 00:50:23+00:00   \n",
       "3 2020-06-05 18:53:43+00:00   \n",
       "4 2020-06-03 19:36:58+00:00   \n",
       "\n",
       "                                         description  category  source  \n",
       "0  Position Summary\\nBlueVolt is growing. We have...       NaN  GitHub  \n",
       "1  Web Developer (The Materials Project) - 90287\\...       NaN  GitHub  \n",
       "2  GAME CLOSURE\\nSan Francisco, Mountain View, To...       NaN  GitHub  \n",
       "3  Thanks for your interest in working with us! D...       NaN  GitHub  \n",
       "4  Humanizing Digital Experiences®\\nKasistos Dig...       NaN  GitHub  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github = pd.read_csv(\"./data/github/github.csv\", sep = \",\", header = 0, parse_dates = [4], encoding = \"ISO-8859-1\")\n",
    "github.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying 'The Muse' jobs data which we stored in the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>link</th>\n",
       "      <th>job_posted</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Advanced Group</td>\n",
       "      <td>SAS Programmer</td>\n",
       "      <td>Flexible / Remote</td>\n",
       "      <td>https://www.themuse.com/jobs/advancedgroup/sas...</td>\n",
       "      <td>2020-05-15 11:13:13.282083+00:00</td>\n",
       "      <td>Advanced Clinical is a global clinical develop...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>The Muse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>The Knot Worldwide</td>\n",
       "      <td>Head of Data Engineering</td>\n",
       "      <td>United States</td>\n",
       "      <td>https://www.themuse.com/jobs/theknotworldwide/...</td>\n",
       "      <td>2020-05-04 23:31:13.547738+00:00</td>\n",
       "      <td>WHAT WE DO MATTERS:\\nHere at The Knot Worldwid...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>The Muse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>b'Collibra'</td>\n",
       "      <td>b'Salesforce Developer'</td>\n",
       "      <td>b'Atlanta, GA'</td>\n",
       "      <td>b'https://www.themuse.com/jobs/collibra/salesf...</td>\n",
       "      <td>2020-06-09 23:02:03.711114+00:00</td>\n",
       "      <td>b\"We're Ushering a New Era of Data Participati...</td>\n",
       "      <td>b'Data Science'</td>\n",
       "      <td>b'The Muse'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Invitae</td>\n",
       "      <td>Biopharma Partnerships Program Manager</td>\n",
       "      <td>Flexible / Remote</td>\n",
       "      <td>https://www.themuse.com/jobs/invitae/biopharma...</td>\n",
       "      <td>2020-06-05 23:02:33.443646+00:00</td>\n",
       "      <td>Invitae is a rapidly growing genetic informati...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>The Muse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Head of Data Science, Insights &amp; Analytics</td>\n",
       "      <td>Flexible / Remote</td>\n",
       "      <td>https://www.themuse.com/jobs/medium/head-of-da...</td>\n",
       "      <td>2020-06-03 13:57:29.821055+00:00</td>\n",
       "      <td>Mediums mission is to help people deepen thei...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>The Muse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              company                                       title  \\\n",
       "0      Advanced Group                              SAS Programmer   \n",
       "1  The Knot Worldwide                    Head of Data Engineering   \n",
       "2         b'Collibra'                     b'Salesforce Developer'   \n",
       "3             Invitae      Biopharma Partnerships Program Manager   \n",
       "4              Medium  Head of Data Science, Insights & Analytics   \n",
       "\n",
       "            location                                               link  \\\n",
       "0  Flexible / Remote  https://www.themuse.com/jobs/advancedgroup/sas...   \n",
       "1      United States  https://www.themuse.com/jobs/theknotworldwide/...   \n",
       "2     b'Atlanta, GA'  b'https://www.themuse.com/jobs/collibra/salesf...   \n",
       "3  Flexible / Remote  https://www.themuse.com/jobs/invitae/biopharma...   \n",
       "4  Flexible / Remote  https://www.themuse.com/jobs/medium/head-of-da...   \n",
       "\n",
       "                        job_posted  \\\n",
       "0 2020-05-15 11:13:13.282083+00:00   \n",
       "1 2020-05-04 23:31:13.547738+00:00   \n",
       "2 2020-06-09 23:02:03.711114+00:00   \n",
       "3 2020-06-05 23:02:33.443646+00:00   \n",
       "4 2020-06-03 13:57:29.821055+00:00   \n",
       "\n",
       "                                         description         category  \\\n",
       "0  Advanced Clinical is a global clinical develop...     Data Science   \n",
       "1  WHAT WE DO MATTERS:\\nHere at The Knot Worldwid...     Data Science   \n",
       "2  b\"We're Ushering a New Era of Data Participati...  b'Data Science'   \n",
       "3  Invitae is a rapidly growing genetic informati...     Data Science   \n",
       "4  Mediums mission is to help people deepen thei...     Data Science   \n",
       "\n",
       "        source  \n",
       "0     The Muse  \n",
       "1     The Muse  \n",
       "2  b'The Muse'  \n",
       "3     The Muse  \n",
       "4     The Muse  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muse = pd.read_csv(\"./data/muse/muse.csv\", sep = \",\", header = 0, parse_dates = [4], encoding = \"ISO-8859-1\")\n",
    "muse.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying USCIS 2019 H-1B employer data which we stored in the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fiscal Year</th>\n",
       "      <th>Employer</th>\n",
       "      <th>Initial Approvals</th>\n",
       "      <th>Initial Denials</th>\n",
       "      <th>Continuing Approvals</th>\n",
       "      <th>Continuing Denials</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>Tax ID</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>ZIP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>SOUTHERN CARPET HARDWOOD &amp; TILE IN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AL</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>35209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>UAB HEALTH SYSTEM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AL</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>35233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>BIRMINGHAM VA MEDICAL CENTER</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AL</td>\n",
       "      <td>BIRMINGHAM</td>\n",
       "      <td>35233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>GESTAMP ALABAMA LLC</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AL</td>\n",
       "      <td>MC CALLA</td>\n",
       "      <td>35111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "      <td>ARKANSAS HEALTH GROUP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AR</td>\n",
       "      <td>LITTLE ROCK</td>\n",
       "      <td>72211.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fiscal Year                            Employer Initial Approvals  \\\n",
       "0         2019  SOUTHERN CARPET HARDWOOD & TILE IN                 1   \n",
       "1         2019                   UAB HEALTH SYSTEM                 0   \n",
       "2         2019        BIRMINGHAM VA MEDICAL CENTER                 0   \n",
       "3         2019                 GESTAMP ALABAMA LLC                 1   \n",
       "4         2019               ARKANSAS HEALTH GROUP                 0   \n",
       "\n",
       "  Initial Denials Continuing Approvals Continuing Denials  NAICS  Tax ID  \\\n",
       "0               0                    0                  0     23     NaN   \n",
       "1               0                    0                  1     56     NaN   \n",
       "2               0                    1                  0     62     NaN   \n",
       "3               0                    0                  0     33     NaN   \n",
       "4               0                    1                  0     62     NaN   \n",
       "\n",
       "  State         City      ZIP  \n",
       "0    AL   BIRMINGHAM  35209.0  \n",
       "1    AL   BIRMINGHAM  35233.0  \n",
       "2    AL   BIRMINGHAM  35233.0  \n",
       "3    AL     MC CALLA  35111.0  \n",
       "4    AR  LITTLE ROCK  72211.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uscis = pd.read_csv(\"./data/uscis/uscis.csv\", sep = \",\", header = 0, encoding = \"ISO-8859-1\")\n",
    "uscis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating all the jobs data collected from `Randstad`, `Adzuna`, `GitHub`, and `The Muse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_data = pd.concat([randstad, adzuna, github, muse])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping duplicate job records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>link</th>\n",
       "      <th>job_posted</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>22189</td>\n",
       "      <td>Socure</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Flexible / Remote</td>\n",
       "      <td>https://www.themuse.com/jobs/socure/senior-dat...</td>\n",
       "      <td>2020-06-11 19:47:18.922553+00:00</td>\n",
       "      <td>\\n\\n\\n\\nFounded in 2012, Socure is the leader ...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>The Muse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22190</td>\n",
       "      <td>Advanced Group</td>\n",
       "      <td>Senior Clinical Data Coordinator</td>\n",
       "      <td>Flexible / Remote</td>\n",
       "      <td>https://www.themuse.com/jobs/advancedgroup/sen...</td>\n",
       "      <td>2020-05-23 11:09:10.789013+00:00</td>\n",
       "      <td>Advanced Clinical is a global clinical develop...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>The Muse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22191</td>\n",
       "      <td>PepsiCo</td>\n",
       "      <td>eCommerce Business Intelligence Intern</td>\n",
       "      <td>United States</td>\n",
       "      <td>https://www.themuse.com/jobs/pepsico/ecommerce...</td>\n",
       "      <td>2020-05-12 21:13:42.378591+00:00</td>\n",
       "      <td>Auto req ID: 191272BR Job Description  We are ...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>The Muse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22192</td>\n",
       "      <td>Guidewire</td>\n",
       "      <td>Actuarial Consultant, Remote USA</td>\n",
       "      <td>Flexible / Remote</td>\n",
       "      <td>https://www.themuse.com/jobs/guidewire/actuari...</td>\n",
       "      <td>2020-05-29 18:44:57.974847+00:00</td>\n",
       "      <td>\\n\\nResponsibilities:This position requires ad...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>The Muse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22193</td>\n",
       "      <td>Invitae</td>\n",
       "      <td>Bioinformatics Engineer, Algorithm</td>\n",
       "      <td>Flexible / Remote</td>\n",
       "      <td>https://www.themuse.com/jobs/invitae/bioinform...</td>\n",
       "      <td>2020-04-30 23:02:35.384368+00:00</td>\n",
       "      <td>\\nInvitae is a healthcare technology company ...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>The Muse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              company                                   title  \\\n",
       "22189          Socure                   Senior Data Scientist   \n",
       "22190  Advanced Group        Senior Clinical Data Coordinator   \n",
       "22191         PepsiCo  eCommerce Business Intelligence Intern   \n",
       "22192       Guidewire        Actuarial Consultant, Remote USA   \n",
       "22193         Invitae      Bioinformatics Engineer, Algorithm   \n",
       "\n",
       "                location                                               link  \\\n",
       "22189  Flexible / Remote  https://www.themuse.com/jobs/socure/senior-dat...   \n",
       "22190  Flexible / Remote  https://www.themuse.com/jobs/advancedgroup/sen...   \n",
       "22191      United States  https://www.themuse.com/jobs/pepsico/ecommerce...   \n",
       "22192  Flexible / Remote  https://www.themuse.com/jobs/guidewire/actuari...   \n",
       "22193  Flexible / Remote  https://www.themuse.com/jobs/invitae/bioinform...   \n",
       "\n",
       "                             job_posted  \\\n",
       "22189  2020-06-11 19:47:18.922553+00:00   \n",
       "22190  2020-05-23 11:09:10.789013+00:00   \n",
       "22191  2020-05-12 21:13:42.378591+00:00   \n",
       "22192  2020-05-29 18:44:57.974847+00:00   \n",
       "22193  2020-04-30 23:02:35.384368+00:00   \n",
       "\n",
       "                                             description      category  \\\n",
       "22189  \\n\\n\\n\\nFounded in 2012, Socure is the leader ...  Data Science   \n",
       "22190  Advanced Clinical is a global clinical develop...  Data Science   \n",
       "22191  Auto req ID: 191272BR Job Description  We are ...  Data Science   \n",
       "22192  \\n\\nResponsibilities:This position requires ad...  Data Science   \n",
       "22193   \\nInvitae is a healthcare technology company ...  Data Science   \n",
       "\n",
       "         source  \n",
       "22189  The Muse  \n",
       "22190  The Muse  \n",
       "22191  The Muse  \n",
       "22192  The Muse  \n",
       "22193  The Muse  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_data = job_data.drop_duplicates(subset=job_data.columns.difference(['source']), keep = \"first\")\n",
    "job_data = job_data.reset_index()\n",
    "job_data.drop('index', axis=1, inplace=True)\n",
    "job_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating below function `mergeWithUSCISData()` which merges jobs data with USCIS data to get the H1B statistics for each company in jobs data.\n",
    "Since company name present in jobs data does not match with USCIS Employer name (Registered Name). We are using 'contains()' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeWithUSCISData(company):\n",
    "    if uscis['Employer'].str.contains(company, na=False, regex=False).any():\n",
    "        row = uscis[uscis['Employer'].str.contains(company, na=False, regex=False, case = False)].iloc[0]\n",
    "\n",
    "        return pd.Series({\n",
    "            'initial_approvals_2019': row['Initial Approvals'],\n",
    "            'initial_denials_2019': row['Initial Denials'],\n",
    "            'continuing_approvals_2019': row['Continuing Approvals'],\n",
    "            'continuing_denials_2019': row['Continuing Denials']\n",
    "        })\n",
    "    else:\n",
    "        return pd.Series({\n",
    "            'initial_approvals_2019': 0,\n",
    "            'initial_denials_2019': 0,\n",
    "            'continuing_approvals_2019': 0,\n",
    "            'continuing_denials_2019': 0\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "uscis['Employer'] = uscis['Employer'].str.lower()\n",
    "company_details = job_data['company'].str.lower().apply(mergeWithUSCISData)\n",
    "job_uscis = pd.concat([job_data, company_details],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for NULL values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company                       True\n",
       "title                        False\n",
       "location                     False\n",
       "link                         False\n",
       "job_posted                   False\n",
       "description                   True\n",
       "category                      True\n",
       "source                       False\n",
       "initial_approvals_2019       False\n",
       "initial_denials_2019         False\n",
       "continuing_approvals_2019    False\n",
       "continuing_denials_2019      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_uscis.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping the rows where company name is NULL. We are not dropping NAs for  'description' and 'category' variables as since it not that important, also we have the link where user can see that particular job posting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_uscis = job_uscis.dropna(subset=['company'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>link</th>\n",
       "      <th>job_posted</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>source</th>\n",
       "      <th>initial_approvals_2019</th>\n",
       "      <th>initial_denials_2019</th>\n",
       "      <th>continuing_approvals_2019</th>\n",
       "      <th>continuing_denials_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>RANDSTAD PROFESSIONALS US L P</td>\n",
       "      <td>sr. data scientist</td>\n",
       "      <td>new york</td>\n",
       "      <td>https://www.randstad.com/jobs/united-states/sr...</td>\n",
       "      <td>2020-06-04 00:00:00</td>\n",
       "      <td>job summary:Our client is looking for dynamic,...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Randstad</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RANDSTAD PROFESSIONALS US L P</td>\n",
       "      <td>business intelligence  analyst</td>\n",
       "      <td>kansas city, missouri</td>\n",
       "      <td>https://www.randstad.com/jobs/united-states/bu...</td>\n",
       "      <td>2020-06-05 00:00:00</td>\n",
       "      <td>job summary:Randstad Technologies is looking f...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Randstad</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RANDSTAD PROFESSIONALS US L P</td>\n",
       "      <td>people research scientist</td>\n",
       "      <td>menlo park, california</td>\n",
       "      <td>https://www.randstad.com/jobs/united-states/pe...</td>\n",
       "      <td>2020-05-26 00:00:00</td>\n",
       "      <td>job summary:Are you a PhD or Master with exper...</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Randstad</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RANDSTAD PROFESSIONALS US L P</td>\n",
       "      <td>people research scientist</td>\n",
       "      <td>new york</td>\n",
       "      <td>https://www.randstad.com/jobs/united-states/pe...</td>\n",
       "      <td>2020-05-26 00:00:00</td>\n",
       "      <td>job summary:Are you a PhD or Master with exper...</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Randstad</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>RANDSTAD PROFESSIONALS US L P</td>\n",
       "      <td>people research scientist</td>\n",
       "      <td>seattle, washington</td>\n",
       "      <td>https://www.randstad.com/jobs/united-states/pe...</td>\n",
       "      <td>2020-05-26 00:00:00</td>\n",
       "      <td>job summary:Are you a PhD or Master with exper...</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Randstad</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22189</td>\n",
       "      <td>Socure</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Flexible / Remote</td>\n",
       "      <td>https://www.themuse.com/jobs/socure/senior-dat...</td>\n",
       "      <td>2020-06-11 19:47:18.922553+00:00</td>\n",
       "      <td>\\n\\n\\n\\nFounded in 2012, Socure is the leader ...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>The Muse</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22190</td>\n",
       "      <td>Advanced Group</td>\n",
       "      <td>Senior Clinical Data Coordinator</td>\n",
       "      <td>Flexible / Remote</td>\n",
       "      <td>https://www.themuse.com/jobs/advancedgroup/sen...</td>\n",
       "      <td>2020-05-23 11:09:10.789013+00:00</td>\n",
       "      <td>Advanced Clinical is a global clinical develop...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>The Muse</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22191</td>\n",
       "      <td>PepsiCo</td>\n",
       "      <td>eCommerce Business Intelligence Intern</td>\n",
       "      <td>United States</td>\n",
       "      <td>https://www.themuse.com/jobs/pepsico/ecommerce...</td>\n",
       "      <td>2020-05-12 21:13:42.378591+00:00</td>\n",
       "      <td>Auto req ID: 191272BR Job Description  We are ...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>The Muse</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22192</td>\n",
       "      <td>Guidewire</td>\n",
       "      <td>Actuarial Consultant, Remote USA</td>\n",
       "      <td>Flexible / Remote</td>\n",
       "      <td>https://www.themuse.com/jobs/guidewire/actuari...</td>\n",
       "      <td>2020-05-29 18:44:57.974847+00:00</td>\n",
       "      <td>\\n\\nResponsibilities:This position requires ad...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>The Muse</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22193</td>\n",
       "      <td>Invitae</td>\n",
       "      <td>Bioinformatics Engineer, Algorithm</td>\n",
       "      <td>Flexible / Remote</td>\n",
       "      <td>https://www.themuse.com/jobs/invitae/bioinform...</td>\n",
       "      <td>2020-04-30 23:02:35.384368+00:00</td>\n",
       "      <td>\\nInvitae is a healthcare technology company ...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>The Muse</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22191 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             company                                   title  \\\n",
       "0      RANDSTAD PROFESSIONALS US L P                      sr. data scientist   \n",
       "1      RANDSTAD PROFESSIONALS US L P          business intelligence  analyst   \n",
       "2      RANDSTAD PROFESSIONALS US L P               people research scientist   \n",
       "3      RANDSTAD PROFESSIONALS US L P               people research scientist   \n",
       "4      RANDSTAD PROFESSIONALS US L P               people research scientist   \n",
       "...                              ...                                     ...   \n",
       "22189                         Socure                   Senior Data Scientist   \n",
       "22190                 Advanced Group        Senior Clinical Data Coordinator   \n",
       "22191                        PepsiCo  eCommerce Business Intelligence Intern   \n",
       "22192                      Guidewire        Actuarial Consultant, Remote USA   \n",
       "22193                        Invitae      Bioinformatics Engineer, Algorithm   \n",
       "\n",
       "                     location  \\\n",
       "0                    new york   \n",
       "1       kansas city, missouri   \n",
       "2      menlo park, california   \n",
       "3                    new york   \n",
       "4         seattle, washington   \n",
       "...                       ...   \n",
       "22189       Flexible / Remote   \n",
       "22190       Flexible / Remote   \n",
       "22191           United States   \n",
       "22192       Flexible / Remote   \n",
       "22193       Flexible / Remote   \n",
       "\n",
       "                                                    link  \\\n",
       "0      https://www.randstad.com/jobs/united-states/sr...   \n",
       "1      https://www.randstad.com/jobs/united-states/bu...   \n",
       "2      https://www.randstad.com/jobs/united-states/pe...   \n",
       "3      https://www.randstad.com/jobs/united-states/pe...   \n",
       "4      https://www.randstad.com/jobs/united-states/pe...   \n",
       "...                                                  ...   \n",
       "22189  https://www.themuse.com/jobs/socure/senior-dat...   \n",
       "22190  https://www.themuse.com/jobs/advancedgroup/sen...   \n",
       "22191  https://www.themuse.com/jobs/pepsico/ecommerce...   \n",
       "22192  https://www.themuse.com/jobs/guidewire/actuari...   \n",
       "22193  https://www.themuse.com/jobs/invitae/bioinform...   \n",
       "\n",
       "                             job_posted  \\\n",
       "0                   2020-06-04 00:00:00   \n",
       "1                   2020-06-05 00:00:00   \n",
       "2                   2020-05-26 00:00:00   \n",
       "3                   2020-05-26 00:00:00   \n",
       "4                   2020-05-26 00:00:00   \n",
       "...                                 ...   \n",
       "22189  2020-06-11 19:47:18.922553+00:00   \n",
       "22190  2020-05-23 11:09:10.789013+00:00   \n",
       "22191  2020-05-12 21:13:42.378591+00:00   \n",
       "22192  2020-05-29 18:44:57.974847+00:00   \n",
       "22193  2020-04-30 23:02:35.384368+00:00   \n",
       "\n",
       "                                             description  \\\n",
       "0      job summary:Our client is looking for dynamic,...   \n",
       "1      job summary:Randstad Technologies is looking f...   \n",
       "2      job summary:Are you a PhD or Master with exper...   \n",
       "3      job summary:Are you a PhD or Master with exper...   \n",
       "4      job summary:Are you a PhD or Master with exper...   \n",
       "...                                                  ...   \n",
       "22189  \\n\\n\\n\\nFounded in 2012, Socure is the leader ...   \n",
       "22190  Advanced Clinical is a global clinical develop...   \n",
       "22191  Auto req ID: 191272BR Job Description  We are ...   \n",
       "22192  \\n\\nResponsibilities:This position requires ad...   \n",
       "22193   \\nInvitae is a healthcare technology company ...   \n",
       "\n",
       "                     category    source initial_approvals_2019  \\\n",
       "0      Information Technology  Randstad                      0   \n",
       "1      Information Technology  Randstad                      0   \n",
       "2             Human Resources  Randstad                      0   \n",
       "3             Human Resources  Randstad                      0   \n",
       "4             Human Resources  Randstad                      0   \n",
       "...                       ...       ...                    ...   \n",
       "22189            Data Science  The Muse                      0   \n",
       "22190            Data Science  The Muse                      0   \n",
       "22191            Data Science  The Muse                      6   \n",
       "22192            Data Science  The Muse                     13   \n",
       "22193            Data Science  The Muse                      1   \n",
       "\n",
       "      initial_denials_2019 continuing_approvals_2019 continuing_denials_2019  \n",
       "0                        0                         1                       0  \n",
       "1                        0                         1                       0  \n",
       "2                        0                         1                       0  \n",
       "3                        0                         1                       0  \n",
       "4                        0                         1                       0  \n",
       "...                    ...                       ...                     ...  \n",
       "22189                    0                         5                       0  \n",
       "22190                    0                         0                       0  \n",
       "22191                    0                        28                       3  \n",
       "22192                    6                        33                       3  \n",
       "22193                    0                         8                       0  \n",
       "\n",
       "[22191 rows x 12 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_uscis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Job Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22191 entries, 0 to 22193\n",
      "Data columns (total 12 columns):\n",
      "company                      22191 non-null object\n",
      "title                        22191 non-null object\n",
      "location                     22191 non-null object\n",
      "link                         22191 non-null object\n",
      "job_posted                   22191 non-null object\n",
      "description                  22190 non-null object\n",
      "category                     22105 non-null object\n",
      "source                       22191 non-null object\n",
      "initial_approvals_2019       22191 non-null object\n",
      "initial_denials_2019         22191 non-null object\n",
      "continuing_approvals_2019    22191 non-null object\n",
      "continuing_denials_2019      22191 non-null object\n",
      "dtypes: object(12)\n",
      "memory usage: 2.2+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>link</th>\n",
       "      <th>job_posted</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>source</th>\n",
       "      <th>initial_approvals_2019</th>\n",
       "      <th>initial_denials_2019</th>\n",
       "      <th>continuing_approvals_2019</th>\n",
       "      <th>continuing_denials_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>22189</td>\n",
       "      <td>Socure</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Flexible / Remote</td>\n",
       "      <td>https://www.themuse.com/jobs/socure/senior-dat...</td>\n",
       "      <td>2020-06-11 19:47:18.922553+00:00</td>\n",
       "      <td>\\n\\n\\n\\nFounded in 2012, Socure is the leader ...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>The Muse</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22190</td>\n",
       "      <td>Advanced Group</td>\n",
       "      <td>Senior Clinical Data Coordinator</td>\n",
       "      <td>Flexible / Remote</td>\n",
       "      <td>https://www.themuse.com/jobs/advancedgroup/sen...</td>\n",
       "      <td>2020-05-23 11:09:10.789013+00:00</td>\n",
       "      <td>Advanced Clinical is a global clinical develop...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>The Muse</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22191</td>\n",
       "      <td>PepsiCo</td>\n",
       "      <td>eCommerce Business Intelligence Intern</td>\n",
       "      <td>United States</td>\n",
       "      <td>https://www.themuse.com/jobs/pepsico/ecommerce...</td>\n",
       "      <td>2020-05-12 21:13:42.378591+00:00</td>\n",
       "      <td>Auto req ID: 191272BR Job Description  We are ...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>The Muse</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22192</td>\n",
       "      <td>Guidewire</td>\n",
       "      <td>Actuarial Consultant, Remote USA</td>\n",
       "      <td>Flexible / Remote</td>\n",
       "      <td>https://www.themuse.com/jobs/guidewire/actuari...</td>\n",
       "      <td>2020-05-29 18:44:57.974847+00:00</td>\n",
       "      <td>\\n\\nResponsibilities:This position requires ad...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>The Muse</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22193</td>\n",
       "      <td>Invitae</td>\n",
       "      <td>Bioinformatics Engineer, Algorithm</td>\n",
       "      <td>Flexible / Remote</td>\n",
       "      <td>https://www.themuse.com/jobs/invitae/bioinform...</td>\n",
       "      <td>2020-04-30 23:02:35.384368+00:00</td>\n",
       "      <td>\\nInvitae is a healthcare technology company ...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>The Muse</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              company                                   title  \\\n",
       "22189          Socure                   Senior Data Scientist   \n",
       "22190  Advanced Group        Senior Clinical Data Coordinator   \n",
       "22191         PepsiCo  eCommerce Business Intelligence Intern   \n",
       "22192       Guidewire        Actuarial Consultant, Remote USA   \n",
       "22193         Invitae      Bioinformatics Engineer, Algorithm   \n",
       "\n",
       "                location                                               link  \\\n",
       "22189  Flexible / Remote  https://www.themuse.com/jobs/socure/senior-dat...   \n",
       "22190  Flexible / Remote  https://www.themuse.com/jobs/advancedgroup/sen...   \n",
       "22191      United States  https://www.themuse.com/jobs/pepsico/ecommerce...   \n",
       "22192  Flexible / Remote  https://www.themuse.com/jobs/guidewire/actuari...   \n",
       "22193  Flexible / Remote  https://www.themuse.com/jobs/invitae/bioinform...   \n",
       "\n",
       "                             job_posted  \\\n",
       "22189  2020-06-11 19:47:18.922553+00:00   \n",
       "22190  2020-05-23 11:09:10.789013+00:00   \n",
       "22191  2020-05-12 21:13:42.378591+00:00   \n",
       "22192  2020-05-29 18:44:57.974847+00:00   \n",
       "22193  2020-04-30 23:02:35.384368+00:00   \n",
       "\n",
       "                                             description      category  \\\n",
       "22189  \\n\\n\\n\\nFounded in 2012, Socure is the leader ...  Data Science   \n",
       "22190  Advanced Clinical is a global clinical develop...  Data Science   \n",
       "22191  Auto req ID: 191272BR Job Description  We are ...  Data Science   \n",
       "22192  \\n\\nResponsibilities:This position requires ad...  Data Science   \n",
       "22193   \\nInvitae is a healthcare technology company ...  Data Science   \n",
       "\n",
       "         source initial_approvals_2019 initial_denials_2019  \\\n",
       "22189  The Muse                      0                    0   \n",
       "22190  The Muse                      0                    0   \n",
       "22191  The Muse                      6                    0   \n",
       "22192  The Muse                     13                    6   \n",
       "22193  The Muse                      1                    0   \n",
       "\n",
       "      continuing_approvals_2019 continuing_denials_2019  \n",
       "22189                         5                       0  \n",
       "22190                         0                       0  \n",
       "22191                        28                       3  \n",
       "22192                        33                       3  \n",
       "22193                         8                       0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(job_uscis.info())\n",
    "job_uscis.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating directory structures for storing final job data. \n",
    "Storing data in './data/job_database/job_database.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/job_database/\"\n",
    "job_data_filename = 'job_database.csv'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "job_uscis.to_csv(path+job_data_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Function for the User to query for jobs.\n",
    "Filters availabe:<br>\n",
    "`title`: Job title.<br>\n",
    "`location`: Job location.<br>\n",
    "`job_posted`: Date of job posting, will return all the records from that date to current date.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchForJobs(title = '', location = '', job_posted=''):\n",
    "    jobs = pd.read_csv(\"./data/job_database/job_database.csv\", sep = \",\", header = 0, parse_dates = [4])\n",
    "    if title:\n",
    "        jobs = jobs[jobs['title'].str.contains('|'.join(title.split()), case = False, na=False)]\n",
    "    if location:\n",
    "        jobs = jobs[jobs['location'].str.contains('|'.join(location.split()), case = False, na=False)]\n",
    "    if job_posted:\n",
    "        #jobs['job_posted'] = jobs['job_posted'].apply(lambda x:dateparser.parse(x).replace(tzinfo=None))\n",
    "        jobs['job_posted'] = jobs['job_posted'].apply(lambda x:x.replace(tzinfo=None))\n",
    "        jobs = jobs[jobs['job_posted'] >= pd.to_datetime(job_posted)]\n",
    "        jobs = jobs.sort_values(by=['initial_approvals_2019', 'continuing_approvals_2019'], ascending=False)\n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching for data scientist jobs in philadelphia which were posted from June 1, 2020 to current date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>link</th>\n",
       "      <th>job_posted</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>source</th>\n",
       "      <th>initial_approvals_2019</th>\n",
       "      <th>initial_denials_2019</th>\n",
       "      <th>continuing_approvals_2019</th>\n",
       "      <th>continuing_denials_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4993</td>\n",
       "      <td>iSolvers Inc</td>\n",
       "      <td>Data Modeler</td>\n",
       "      <td>Philadelphia County, Pennsylvania</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1568369498?se=y...</td>\n",
       "      <td>2020-06-09 10:22:07</td>\n",
       "      <td>-models for analytics pipelines andor data-sci...</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9346</td>\n",
       "      <td>iSolvers Inc</td>\n",
       "      <td>Data Modeler</td>\n",
       "      <td>Philadelphia County, Pennsylvania</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1572433263?se=q...</td>\n",
       "      <td>2020-06-13 09:03:52</td>\n",
       "      <td>-models for analytics pipelines andor data-sci...</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4032</td>\n",
       "      <td>GlaxoSmithKline</td>\n",
       "      <td>Director Supply Chain Data Science &amp; Network O...</td>\n",
       "      <td>Philadelphia County, Pennsylvania</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1569394434?se=D...</td>\n",
       "      <td>2020-06-10 06:25:49</td>\n",
       "      <td>Job description Site Name: USA - Pennsylvania ...</td>\n",
       "      <td>Energy, Oil &amp; Gas Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5231</td>\n",
       "      <td>Resource Informatics Group</td>\n",
       "      <td>BigData Architect</td>\n",
       "      <td>Philadelphia County, Pennsylvania</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1560172723?se=4...</td>\n",
       "      <td>2020-06-01 03:46:32</td>\n",
       "      <td>...  quality efforts. bull Work closely with t...</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1961</td>\n",
       "      <td>Varsity Tutors</td>\n",
       "      <td>Data Science Tutor Jobs</td>\n",
       "      <td>Middle West, Philadelphia County</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1560834256?se=v...</td>\n",
       "      <td>2020-06-01 17:35:23</td>\n",
       "      <td>Delaware County Data Science Tutor Jobs Varsit...</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1962</td>\n",
       "      <td>Varsity Tutors</td>\n",
       "      <td>Data Science Tutor Jobs</td>\n",
       "      <td>Middle West, Philadelphia County</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1560834967?se=v...</td>\n",
       "      <td>2020-06-01 17:35:30</td>\n",
       "      <td>Chester County Data Science Tutor Jobs Varsity...</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1963</td>\n",
       "      <td>Varsity Tutors</td>\n",
       "      <td>Data Science Tutor Jobs</td>\n",
       "      <td>Middle West, Philadelphia County</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1560836520?se=v...</td>\n",
       "      <td>2020-06-01 17:35:45</td>\n",
       "      <td>Montgomery County Data Science Tutor Jobs Vars...</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1964</td>\n",
       "      <td>Varsity Tutors</td>\n",
       "      <td>Data Science Tutor Jobs</td>\n",
       "      <td>Middle West, Philadelphia County</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1560837132?se=v...</td>\n",
       "      <td>2020-06-01 17:35:52</td>\n",
       "      <td>Radnor Data Science Tutor Jobs Varsity Tutors ...</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1965</td>\n",
       "      <td>Varsity Tutors</td>\n",
       "      <td>Data Science Tutor Jobs</td>\n",
       "      <td>Middle West, Philadelphia County</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1560837654?se=v...</td>\n",
       "      <td>2020-06-01 17:36:01</td>\n",
       "      <td>West Chester Data Science Tutor Jobs Varsity T...</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1966</td>\n",
       "      <td>Varsity Tutors</td>\n",
       "      <td>Data Science Tutor Jobs</td>\n",
       "      <td>Middle West, Philadelphia County</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1560837748?se=v...</td>\n",
       "      <td>2020-06-01 17:36:03</td>\n",
       "      <td>Springfield Data Science Tutor Jobs Varsity Tu...</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1967</td>\n",
       "      <td>Varsity Tutors</td>\n",
       "      <td>Data Science Tutor Jobs</td>\n",
       "      <td>Middle West, Philadelphia County</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1560838652?se=4...</td>\n",
       "      <td>2020-06-01 17:36:23</td>\n",
       "      <td>Newtown Data Science Tutor Jobs Varsity Tutors...</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1968</td>\n",
       "      <td>Varsity Tutors</td>\n",
       "      <td>Data Science Tutor Jobs</td>\n",
       "      <td>Middle West, Philadelphia County</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1560839012?se=4...</td>\n",
       "      <td>2020-06-01 17:36:31</td>\n",
       "      <td>Doylestown Data Science Tutor Jobs Varsity Tut...</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1972</td>\n",
       "      <td>Varsity Tutors</td>\n",
       "      <td>Data Science Tutor Jobs</td>\n",
       "      <td>Middle West, Philadelphia County</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1560844591?se=4...</td>\n",
       "      <td>2020-06-01 17:37:48</td>\n",
       "      <td>New Jersey Data Science Tutor Jobs Varsity Tut...</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1984</td>\n",
       "      <td>Varsity Tutors</td>\n",
       "      <td>Data Science Tutor Jobs</td>\n",
       "      <td>Middle West, Philadelphia County</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1560835751?se=F...</td>\n",
       "      <td>2020-06-01 17:35:37</td>\n",
       "      <td>Bucks County Data Science Tutor Jobs Varsity T...</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1986</td>\n",
       "      <td>Varsity Tutors</td>\n",
       "      <td>Data Science Tutor Jobs</td>\n",
       "      <td>Middle West, Philadelphia County</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1560838140?se=F...</td>\n",
       "      <td>2020-06-01 17:36:11</td>\n",
       "      <td>Downingtown Data Science Tutor Jobs Varsity Tu...</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1987</td>\n",
       "      <td>Varsity Tutors</td>\n",
       "      <td>Data Science Tutor Jobs</td>\n",
       "      <td>Middle West, Philadelphia County</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1560839328?se=C...</td>\n",
       "      <td>2020-06-01 17:36:37</td>\n",
       "      <td>King of Prussia Data Science Tutor Jobs Varsit...</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017</td>\n",
       "      <td>Varsity Tutors</td>\n",
       "      <td>Data Science Tutor Jobs</td>\n",
       "      <td>Middle West, Philadelphia County</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1560838690?se=p...</td>\n",
       "      <td>2020-06-01 17:36:24</td>\n",
       "      <td>Ambler Data Science Tutor Jobs Varsity Tutors ...</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2048</td>\n",
       "      <td>Varsity Tutors</td>\n",
       "      <td>Data Science Tutor Jobs</td>\n",
       "      <td>Middle West, Philadelphia County</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1560889412?se=L...</td>\n",
       "      <td>2020-06-01 17:45:41</td>\n",
       "      <td>Philadelphia Data Science Tutor Jobs Varsity T...</td>\n",
       "      <td>Teaching Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8587</td>\n",
       "      <td>IT Pros</td>\n",
       "      <td>Healthcare Data Architect - Series C $40MM Tec...</td>\n",
       "      <td>Philadelphia County, Pennsylvania</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1567367710?se=j...</td>\n",
       "      <td>2020-06-08 10:32:40</td>\n",
       "      <td>Job Description The Data Architect will be han...</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1428</td>\n",
       "      <td>Thermo Fisher Scientific</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Philadelphia County, Pennsylvania</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1569456686?se=2...</td>\n",
       "      <td>2020-06-10 07:40:36</td>\n",
       "      <td>What You Will A Part Of: The IT Data Science A...</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1464</td>\n",
       "      <td>Comcast</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Philadelphia County, Pennsylvania</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1567233330?se=D...</td>\n",
       "      <td>2020-06-08 07:30:29</td>\n",
       "      <td>...  and prioritization for new and existing d...</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1495</td>\n",
       "      <td>Comcast</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Philadelphia County, Pennsylvania</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1569468822?se=v...</td>\n",
       "      <td>2020-06-10 08:04:28</td>\n",
       "      <td>...  years of meaningful work experience in da...</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>387</td>\n",
       "      <td>Computer Enterprises, Inc.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Philadelphia County, Pennsylvania</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1560175635?se=m...</td>\n",
       "      <td>2020-06-01 03:47:04</td>\n",
       "      <td>Data Scientist Location Philadelphia PA 19103 ...</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>Pyramid Consulting, Inc.</td>\n",
       "      <td>Data Scientist (Python/Data Science/ELK)</td>\n",
       "      <td>Philadelphia County, Pennsylvania</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1560156996?se=K...</td>\n",
       "      <td>2020-06-01 03:43:50</td>\n",
       "      <td>Immediate need for a talented Data Scientist (...</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1319</td>\n",
       "      <td>Computer Enterprises, Inc.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Philadelphia County, Pennsylvania</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1569703820?se=R...</td>\n",
       "      <td>2020-06-10 10:35:34</td>\n",
       "      <td>Data Scientist Location Philadelphia PA 19103 ...</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1646</td>\n",
       "      <td>Pyramid Consulting, Inc.</td>\n",
       "      <td>Data Scientist (Python/Data Science/ELK)</td>\n",
       "      <td>Philadelphia County, Pennsylvania</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1569696265?se=X...</td>\n",
       "      <td>2020-06-10 10:23:14</td>\n",
       "      <td>Immediate need for a talented Data Scientist (...</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4714</td>\n",
       "      <td>Computer Enterprises, Inc.</td>\n",
       "      <td>Big Data Architect</td>\n",
       "      <td>Philadelphia County, Pennsylvania</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1560168297?se=M...</td>\n",
       "      <td>2020-06-01 03:45:48</td>\n",
       "      <td>, developers, architects, and engineers to sup...</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4716</td>\n",
       "      <td>Apidel Technologies</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Philadelphia County, Pennsylvania</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1560140083?se=-...</td>\n",
       "      <td>2020-06-01 03:41:00</td>\n",
       "      <td>...  which I have mentioned below. Title Data ...</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5115</td>\n",
       "      <td>A2C Consulting</td>\n",
       "      <td>Senior data engineer</td>\n",
       "      <td>Philadelphia County, Pennsylvania</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1560155551?se=j...</td>\n",
       "      <td>2020-06-01 03:43:35</td>\n",
       "      <td>Business Intelligence team needs Data Engineer...</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5116</td>\n",
       "      <td>A2C Consulting</td>\n",
       "      <td>Senior data engineer</td>\n",
       "      <td>Philadelphia County, Pennsylvania</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1560155551?se=s...</td>\n",
       "      <td>2020-06-01 03:43:35</td>\n",
       "      <td>Business Intelligence team needs Data Engineer...</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5455</td>\n",
       "      <td>The Judge Group, Inc.</td>\n",
       "      <td>AWS Big Data Architect</td>\n",
       "      <td>Philadelphia County, Pennsylvania</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1560176843?se=p...</td>\n",
       "      <td>2020-06-01 03:47:16</td>\n",
       "      <td>...  closely with the Data Science team to imp...</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6241</td>\n",
       "      <td>Piano</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>William Penn Annex West, Philadelphia County</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1568682837?se=p...</td>\n",
       "      <td>2020-06-09 19:35:52</td>\n",
       "      <td>, JavaScript work  Analytical thinking and abi...</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7938</td>\n",
       "      <td>Apidel Technologies</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Philadelphia County, Pennsylvania</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1572379722?se=P...</td>\n",
       "      <td>2020-06-13 08:31:54</td>\n",
       "      <td>...  which I have mentioned below. Title Data ...</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11620</td>\n",
       "      <td>The Judge Group, Inc.</td>\n",
       "      <td>AWS Big Data Architect</td>\n",
       "      <td>Philadelphia County, Pennsylvania</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1572379901?se=6...</td>\n",
       "      <td>2020-06-13 08:31:59</td>\n",
       "      <td>...  closely with the Data Science team to imp...</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19266</td>\n",
       "      <td>LEO Pharma</td>\n",
       "      <td>Director, Payer Pharmacy Data &amp; Analytics</td>\n",
       "      <td>Philadelphia County, Pennsylvania</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1572346626?se=M...</td>\n",
       "      <td>2020-06-13 07:50:00</td>\n",
       "      <td>...  theoretical and applied) and/or analysis ...</td>\n",
       "      <td>Healthcare &amp; Nursing Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19716</td>\n",
       "      <td>Merck</td>\n",
       "      <td>Associate Principal Scientist, Outcomes Research</td>\n",
       "      <td>Philadelphia County, Pennsylvania</td>\n",
       "      <td>https://www.adzuna.com/land/ad/1566547647?se=P...</td>\n",
       "      <td>2020-06-07 07:32:55</td>\n",
       "      <td>, providers, and patients. The Associate Princ...</td>\n",
       "      <td>Scientific &amp; QA Jobs</td>\n",
       "      <td>Adzuna</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          company  \\\n",
       "4993                 iSolvers Inc   \n",
       "9346                 iSolvers Inc   \n",
       "4032              GlaxoSmithKline   \n",
       "5231   Resource Informatics Group   \n",
       "1961               Varsity Tutors   \n",
       "1962               Varsity Tutors   \n",
       "1963               Varsity Tutors   \n",
       "1964               Varsity Tutors   \n",
       "1965               Varsity Tutors   \n",
       "1966               Varsity Tutors   \n",
       "1967               Varsity Tutors   \n",
       "1968               Varsity Tutors   \n",
       "1972               Varsity Tutors   \n",
       "1984               Varsity Tutors   \n",
       "1986               Varsity Tutors   \n",
       "1987               Varsity Tutors   \n",
       "2017               Varsity Tutors   \n",
       "2048               Varsity Tutors   \n",
       "8587                      IT Pros   \n",
       "1428     Thermo Fisher Scientific   \n",
       "1464                      Comcast   \n",
       "1495                      Comcast   \n",
       "387    Computer Enterprises, Inc.   \n",
       "448      Pyramid Consulting, Inc.   \n",
       "1319   Computer Enterprises, Inc.   \n",
       "1646     Pyramid Consulting, Inc.   \n",
       "4714   Computer Enterprises, Inc.   \n",
       "4716          Apidel Technologies   \n",
       "5115               A2C Consulting   \n",
       "5116               A2C Consulting   \n",
       "5455        The Judge Group, Inc.   \n",
       "6241                        Piano   \n",
       "7938          Apidel Technologies   \n",
       "11620       The Judge Group, Inc.   \n",
       "19266                  LEO Pharma   \n",
       "19716                       Merck   \n",
       "\n",
       "                                                   title  \\\n",
       "4993                                        Data Modeler   \n",
       "9346                                        Data Modeler   \n",
       "4032   Director Supply Chain Data Science & Network O...   \n",
       "5231                                   BigData Architect   \n",
       "1961                             Data Science Tutor Jobs   \n",
       "1962                             Data Science Tutor Jobs   \n",
       "1963                             Data Science Tutor Jobs   \n",
       "1964                             Data Science Tutor Jobs   \n",
       "1965                             Data Science Tutor Jobs   \n",
       "1966                             Data Science Tutor Jobs   \n",
       "1967                             Data Science Tutor Jobs   \n",
       "1968                             Data Science Tutor Jobs   \n",
       "1972                             Data Science Tutor Jobs   \n",
       "1984                             Data Science Tutor Jobs   \n",
       "1986                             Data Science Tutor Jobs   \n",
       "1987                             Data Science Tutor Jobs   \n",
       "2017                             Data Science Tutor Jobs   \n",
       "2048                             Data Science Tutor Jobs   \n",
       "8587   Healthcare Data Architect - Series C $40MM Tec...   \n",
       "1428                                      Data Scientist   \n",
       "1464                                      Data Scientist   \n",
       "1495                                      Data Scientist   \n",
       "387                                       Data Scientist   \n",
       "448             Data Scientist (Python/Data Science/ELK)   \n",
       "1319                                      Data Scientist   \n",
       "1646            Data Scientist (Python/Data Science/ELK)   \n",
       "4714                                  Big Data Architect   \n",
       "4716                                       Data Engineer   \n",
       "5115                                Senior data engineer   \n",
       "5116                                Senior data engineer   \n",
       "5455                              AWS Big Data Architect   \n",
       "6241                                        Data Analyst   \n",
       "7938                                       Data Engineer   \n",
       "11620                             AWS Big Data Architect   \n",
       "19266          Director, Payer Pharmacy Data & Analytics   \n",
       "19716   Associate Principal Scientist, Outcomes Research   \n",
       "\n",
       "                                           location  \\\n",
       "4993              Philadelphia County, Pennsylvania   \n",
       "9346              Philadelphia County, Pennsylvania   \n",
       "4032              Philadelphia County, Pennsylvania   \n",
       "5231              Philadelphia County, Pennsylvania   \n",
       "1961               Middle West, Philadelphia County   \n",
       "1962               Middle West, Philadelphia County   \n",
       "1963               Middle West, Philadelphia County   \n",
       "1964               Middle West, Philadelphia County   \n",
       "1965               Middle West, Philadelphia County   \n",
       "1966               Middle West, Philadelphia County   \n",
       "1967               Middle West, Philadelphia County   \n",
       "1968               Middle West, Philadelphia County   \n",
       "1972               Middle West, Philadelphia County   \n",
       "1984               Middle West, Philadelphia County   \n",
       "1986               Middle West, Philadelphia County   \n",
       "1987               Middle West, Philadelphia County   \n",
       "2017               Middle West, Philadelphia County   \n",
       "2048               Middle West, Philadelphia County   \n",
       "8587              Philadelphia County, Pennsylvania   \n",
       "1428              Philadelphia County, Pennsylvania   \n",
       "1464              Philadelphia County, Pennsylvania   \n",
       "1495              Philadelphia County, Pennsylvania   \n",
       "387               Philadelphia County, Pennsylvania   \n",
       "448               Philadelphia County, Pennsylvania   \n",
       "1319              Philadelphia County, Pennsylvania   \n",
       "1646              Philadelphia County, Pennsylvania   \n",
       "4714              Philadelphia County, Pennsylvania   \n",
       "4716              Philadelphia County, Pennsylvania   \n",
       "5115              Philadelphia County, Pennsylvania   \n",
       "5116              Philadelphia County, Pennsylvania   \n",
       "5455              Philadelphia County, Pennsylvania   \n",
       "6241   William Penn Annex West, Philadelphia County   \n",
       "7938              Philadelphia County, Pennsylvania   \n",
       "11620             Philadelphia County, Pennsylvania   \n",
       "19266             Philadelphia County, Pennsylvania   \n",
       "19716             Philadelphia County, Pennsylvania   \n",
       "\n",
       "                                                    link          job_posted  \\\n",
       "4993   https://www.adzuna.com/land/ad/1568369498?se=y... 2020-06-09 10:22:07   \n",
       "9346   https://www.adzuna.com/land/ad/1572433263?se=q... 2020-06-13 09:03:52   \n",
       "4032   https://www.adzuna.com/land/ad/1569394434?se=D... 2020-06-10 06:25:49   \n",
       "5231   https://www.adzuna.com/land/ad/1560172723?se=4... 2020-06-01 03:46:32   \n",
       "1961   https://www.adzuna.com/land/ad/1560834256?se=v... 2020-06-01 17:35:23   \n",
       "1962   https://www.adzuna.com/land/ad/1560834967?se=v... 2020-06-01 17:35:30   \n",
       "1963   https://www.adzuna.com/land/ad/1560836520?se=v... 2020-06-01 17:35:45   \n",
       "1964   https://www.adzuna.com/land/ad/1560837132?se=v... 2020-06-01 17:35:52   \n",
       "1965   https://www.adzuna.com/land/ad/1560837654?se=v... 2020-06-01 17:36:01   \n",
       "1966   https://www.adzuna.com/land/ad/1560837748?se=v... 2020-06-01 17:36:03   \n",
       "1967   https://www.adzuna.com/land/ad/1560838652?se=4... 2020-06-01 17:36:23   \n",
       "1968   https://www.adzuna.com/land/ad/1560839012?se=4... 2020-06-01 17:36:31   \n",
       "1972   https://www.adzuna.com/land/ad/1560844591?se=4... 2020-06-01 17:37:48   \n",
       "1984   https://www.adzuna.com/land/ad/1560835751?se=F... 2020-06-01 17:35:37   \n",
       "1986   https://www.adzuna.com/land/ad/1560838140?se=F... 2020-06-01 17:36:11   \n",
       "1987   https://www.adzuna.com/land/ad/1560839328?se=C... 2020-06-01 17:36:37   \n",
       "2017   https://www.adzuna.com/land/ad/1560838690?se=p... 2020-06-01 17:36:24   \n",
       "2048   https://www.adzuna.com/land/ad/1560889412?se=L... 2020-06-01 17:45:41   \n",
       "8587   https://www.adzuna.com/land/ad/1567367710?se=j... 2020-06-08 10:32:40   \n",
       "1428   https://www.adzuna.com/land/ad/1569456686?se=2... 2020-06-10 07:40:36   \n",
       "1464   https://www.adzuna.com/land/ad/1567233330?se=D... 2020-06-08 07:30:29   \n",
       "1495   https://www.adzuna.com/land/ad/1569468822?se=v... 2020-06-10 08:04:28   \n",
       "387    https://www.adzuna.com/land/ad/1560175635?se=m... 2020-06-01 03:47:04   \n",
       "448    https://www.adzuna.com/land/ad/1560156996?se=K... 2020-06-01 03:43:50   \n",
       "1319   https://www.adzuna.com/land/ad/1569703820?se=R... 2020-06-10 10:35:34   \n",
       "1646   https://www.adzuna.com/land/ad/1569696265?se=X... 2020-06-10 10:23:14   \n",
       "4714   https://www.adzuna.com/land/ad/1560168297?se=M... 2020-06-01 03:45:48   \n",
       "4716   https://www.adzuna.com/land/ad/1560140083?se=-... 2020-06-01 03:41:00   \n",
       "5115   https://www.adzuna.com/land/ad/1560155551?se=j... 2020-06-01 03:43:35   \n",
       "5116   https://www.adzuna.com/land/ad/1560155551?se=s... 2020-06-01 03:43:35   \n",
       "5455   https://www.adzuna.com/land/ad/1560176843?se=p... 2020-06-01 03:47:16   \n",
       "6241   https://www.adzuna.com/land/ad/1568682837?se=p... 2020-06-09 19:35:52   \n",
       "7938   https://www.adzuna.com/land/ad/1572379722?se=P... 2020-06-13 08:31:54   \n",
       "11620  https://www.adzuna.com/land/ad/1572379901?se=6... 2020-06-13 08:31:59   \n",
       "19266  https://www.adzuna.com/land/ad/1572346626?se=M... 2020-06-13 07:50:00   \n",
       "19716  https://www.adzuna.com/land/ad/1566547647?se=P... 2020-06-07 07:32:55   \n",
       "\n",
       "                                             description  \\\n",
       "4993   -models for analytics pipelines andor data-sci...   \n",
       "9346   -models for analytics pipelines andor data-sci...   \n",
       "4032   Job description Site Name: USA - Pennsylvania ...   \n",
       "5231   ...  quality efforts. bull Work closely with t...   \n",
       "1961   Delaware County Data Science Tutor Jobs Varsit...   \n",
       "1962   Chester County Data Science Tutor Jobs Varsity...   \n",
       "1963   Montgomery County Data Science Tutor Jobs Vars...   \n",
       "1964   Radnor Data Science Tutor Jobs Varsity Tutors ...   \n",
       "1965   West Chester Data Science Tutor Jobs Varsity T...   \n",
       "1966   Springfield Data Science Tutor Jobs Varsity Tu...   \n",
       "1967   Newtown Data Science Tutor Jobs Varsity Tutors...   \n",
       "1968   Doylestown Data Science Tutor Jobs Varsity Tut...   \n",
       "1972   New Jersey Data Science Tutor Jobs Varsity Tut...   \n",
       "1984   Bucks County Data Science Tutor Jobs Varsity T...   \n",
       "1986   Downingtown Data Science Tutor Jobs Varsity Tu...   \n",
       "1987   King of Prussia Data Science Tutor Jobs Varsit...   \n",
       "2017   Ambler Data Science Tutor Jobs Varsity Tutors ...   \n",
       "2048   Philadelphia Data Science Tutor Jobs Varsity T...   \n",
       "8587   Job Description The Data Architect will be han...   \n",
       "1428   What You Will A Part Of: The IT Data Science A...   \n",
       "1464   ...  and prioritization for new and existing d...   \n",
       "1495   ...  years of meaningful work experience in da...   \n",
       "387    Data Scientist Location Philadelphia PA 19103 ...   \n",
       "448    Immediate need for a talented Data Scientist (...   \n",
       "1319   Data Scientist Location Philadelphia PA 19103 ...   \n",
       "1646   Immediate need for a talented Data Scientist (...   \n",
       "4714   , developers, architects, and engineers to sup...   \n",
       "4716   ...  which I have mentioned below. Title Data ...   \n",
       "5115   Business Intelligence team needs Data Engineer...   \n",
       "5116   Business Intelligence team needs Data Engineer...   \n",
       "5455   ...  closely with the Data Science team to imp...   \n",
       "6241   , JavaScript work  Analytical thinking and abi...   \n",
       "7938   ...  which I have mentioned below. Title Data ...   \n",
       "11620  ...  closely with the Data Science team to imp...   \n",
       "19266  ...  theoretical and applied) and/or analysis ...   \n",
       "19716  , providers, and patients. The Associate Princ...   \n",
       "\n",
       "                        category  source  initial_approvals_2019  \\\n",
       "4993                     IT Jobs  Adzuna                      11   \n",
       "9346                     IT Jobs  Adzuna                      11   \n",
       "4032      Energy, Oil & Gas Jobs  Adzuna                      10   \n",
       "5231                     IT Jobs  Adzuna                       8   \n",
       "1961               Teaching Jobs  Adzuna                       3   \n",
       "1962               Teaching Jobs  Adzuna                       3   \n",
       "1963               Teaching Jobs  Adzuna                       3   \n",
       "1964               Teaching Jobs  Adzuna                       3   \n",
       "1965               Teaching Jobs  Adzuna                       3   \n",
       "1966               Teaching Jobs  Adzuna                       3   \n",
       "1967               Teaching Jobs  Adzuna                       3   \n",
       "1968               Teaching Jobs  Adzuna                       3   \n",
       "1972               Teaching Jobs  Adzuna                       3   \n",
       "1984               Teaching Jobs  Adzuna                       3   \n",
       "1986               Teaching Jobs  Adzuna                       3   \n",
       "1987               Teaching Jobs  Adzuna                       3   \n",
       "2017               Teaching Jobs  Adzuna                       3   \n",
       "2048               Teaching Jobs  Adzuna                       3   \n",
       "8587                     IT Jobs  Adzuna                       1   \n",
       "1428                     IT Jobs  Adzuna                       0   \n",
       "1464                     IT Jobs  Adzuna                       0   \n",
       "1495                     IT Jobs  Adzuna                       0   \n",
       "387                      IT Jobs  Adzuna                       0   \n",
       "448                      IT Jobs  Adzuna                       0   \n",
       "1319                     IT Jobs  Adzuna                       0   \n",
       "1646                     IT Jobs  Adzuna                       0   \n",
       "4714                     IT Jobs  Adzuna                       0   \n",
       "4716                     IT Jobs  Adzuna                       0   \n",
       "5115                     IT Jobs  Adzuna                       0   \n",
       "5116                     IT Jobs  Adzuna                       0   \n",
       "5455                     IT Jobs  Adzuna                       0   \n",
       "6241                     IT Jobs  Adzuna                       0   \n",
       "7938                     IT Jobs  Adzuna                       0   \n",
       "11620                    IT Jobs  Adzuna                       0   \n",
       "19266  Healthcare & Nursing Jobs  Adzuna                       0   \n",
       "19716       Scientific & QA Jobs  Adzuna                       0   \n",
       "\n",
       "       initial_denials_2019  continuing_approvals_2019  \\\n",
       "4993                      0                          9   \n",
       "9346                      0                          9   \n",
       "4032                      1                         32   \n",
       "5231                     22                          9   \n",
       "1961                      0                          0   \n",
       "1962                      0                          0   \n",
       "1963                      0                          0   \n",
       "1964                      0                          0   \n",
       "1965                      0                          0   \n",
       "1966                      0                          0   \n",
       "1967                      0                          0   \n",
       "1968                      0                          0   \n",
       "1972                      0                          0   \n",
       "1984                      0                          0   \n",
       "1986                      0                          0   \n",
       "1987                      0                          0   \n",
       "2017                      0                          0   \n",
       "2048                      0                          0   \n",
       "8587                      3                          0   \n",
       "1428                      0                          2   \n",
       "1464                      0                          1   \n",
       "1495                      0                          1   \n",
       "387                       0                          0   \n",
       "448                       0                          0   \n",
       "1319                      0                          0   \n",
       "1646                      0                          0   \n",
       "4714                      0                          0   \n",
       "4716                      0                          0   \n",
       "5115                      0                          0   \n",
       "5116                      0                          0   \n",
       "5455                      0                          0   \n",
       "6241                      1                          0   \n",
       "7938                      0                          0   \n",
       "11620                     0                          0   \n",
       "19266                     0                          0   \n",
       "19716                     1                          0   \n",
       "\n",
       "       continuing_denials_2019  \n",
       "4993                         2  \n",
       "9346                         2  \n",
       "4032                         3  \n",
       "5231                        11  \n",
       "1961                         0  \n",
       "1962                         0  \n",
       "1963                         0  \n",
       "1964                         0  \n",
       "1965                         0  \n",
       "1966                         0  \n",
       "1967                         0  \n",
       "1968                         0  \n",
       "1972                         0  \n",
       "1984                         0  \n",
       "1986                         0  \n",
       "1987                         0  \n",
       "2017                         0  \n",
       "2048                         0  \n",
       "8587                         0  \n",
       "1428                         1  \n",
       "1464                         0  \n",
       "1495                         0  \n",
       "387                          0  \n",
       "448                          0  \n",
       "1319                         0  \n",
       "1646                         0  \n",
       "4714                         0  \n",
       "4716                         0  \n",
       "5115                         0  \n",
       "5116                         0  \n",
       "5455                         0  \n",
       "6241                         0  \n",
       "7938                         0  \n",
       "11620                        0  \n",
       "19266                        0  \n",
       "19716                        0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchForJobs('Data Scientist', 'Philadelphia', '2020-06-01')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
